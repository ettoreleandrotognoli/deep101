{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "timestamp = int(time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos os dados já embaralhados divididos em train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos as entradas pra `float` (pra poder manipular), adicionamos a dimensão do canal e pré-tratamos\n",
    "Como temos um intervalo definido de entrada [0, 255], simplesmente mudamos a escala para [0, 1], o que é bem comum de se fazer em imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos os labels pra one-hot encoding (vetor 10-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de entrada (compatível com a forma de x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = entry = Input(shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camadas de convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Conv2D(32, kernel_size=3, strides=1)(out)\n",
    "out = Activation('relu')(out)\n",
    "out = MaxPool2D()(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de saída com 10 neurônios, cada um responsável por um dígito e aplicação do softmax para obtermos uma distribuição de probabilidade\n",
    "\n",
    "Antes, transformamos o tensor em um vetor unidimensional. Isso  é necessário para podermos aplicar uma camada densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Flatten()(out)\n",
    "\n",
    "out = Dense(10)(out)\n",
    "out = Activation('softmax')(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do modelo em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(entry, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos a descrição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do custo e da otimização\n",
    "Custo é a cross-entropia entre saída e resposta\n",
    "Otimização é a descida de gradientes estocástica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=60,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('save/mnist.{epoch:02d}.h5'),\n",
    "        TensorBoard(log_dir='logs/mnist_{}'.format(timestamp), histogram_freq=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega a imagem, converte para escala de cinza e redimensiona para o tamanho da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = load_img('data/5.png', grayscale=True, target_size=net.input_shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria a entrada e infere a saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(image, (1, 28, 28, 1))\n",
    "y = net.predict(x, verbose=0)[0]\n",
    "\n",
    "print('É um', np.argmax(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
